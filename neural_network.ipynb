{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models, layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.load('fashion_train.npy')\n",
    "test = np.load('fashion_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_x_y(data):\n",
    "    Y = data[:, -1]\n",
    "    X = np.delete(data, -1, axis=1)\n",
    "    return X, Y\n",
    "\n",
    "label_dict = {0: 'T_shirts', 1: 'Trouseres', 2: 'Pullover', 3: 'Dress', 4: 'Shirt'}\n",
    "\n",
    "train_x, train_y = find_x_y(train)\n",
    "test_x, test_y = find_x_y(test)\n",
    "\n",
    "def compute_class_weights(y):\n",
    "    class_counts = np.bincount(y)\n",
    "    total_samples = len(y)\n",
    "    class_weights = total_samples / (len(class_counts) * class_counts)\n",
    "    return class_weights\n",
    "\n",
    "# Flatten the class labels to avoid the TypeError\n",
    "flat_train_y = train_y.flatten()\n",
    "class_weights = compute_class_weights(flat_train_y)\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "\n",
    "train_x = train_x.reshape((10000, 28, 28, 1))\n",
    "train_x = train_x.astype('float32') / 255\n",
    "\n",
    "test_x = test_x.reshape((5000, 28, 28, 1))\n",
    "test_x = test_x.astype('float32') / 255\n",
    "\n",
    "train_y = to_categorical(train_y)\n",
    "test_y = to_categorical(test_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_15 (Conv2D)          (None, 26, 26, 64)        640       \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPooli  (None, 13, 13, 64)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 11, 11, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPooli  (None, 5, 5, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 3, 3, 128)         73856     \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 1152)              0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 128)               147584    \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 259653 (1014.27 KB)\n",
      "Trainable params: 259653 (1014.27 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "#model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "#model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "#model.add(layers.BatchNormalization())\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "#model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dense(5, activation='softmax'))\n",
    "#model.add(layers.BatchNormalization())\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    \"\"\"\n",
    "    Returns a custom learning rate that decreases as epochs progress.\n",
    "    \"\"\"\n",
    "    initial_lr = 0.001\n",
    "    drop = 0.5\n",
    "    epochs_drop = 5\n",
    "    lr = initial_lr * drop ** (epoch / epochs_drop)\n",
    "    return lr\n",
    "\n",
    "# Set up the learning rate scheduler callback\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.6179 - accuracy: 0.7465\n",
      "Epoch 1: val_accuracy improved from -inf to 0.82840, saving model to best_model.h5\n",
      "313/313 [==============================] - 5s 13ms/step - loss: 0.6175 - accuracy: 0.7467 - val_loss: 0.4531 - val_accuracy: 0.8284 - lr: 0.0010\n",
      "Epoch 2/50\n",
      " 11/313 [>.............................] - ETA: 3s - loss: 0.4178 - accuracy: 0.8381"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kubic\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312/313 [============================>.] - ETA: 0s - loss: 0.3961 - accuracy: 0.8509\n",
      "Epoch 2: val_accuracy improved from 0.82840 to 0.84900, saving model to best_model.h5\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.3959 - accuracy: 0.8510 - val_loss: 0.4041 - val_accuracy: 0.8490 - lr: 8.7055e-04\n",
      "Epoch 3/50\n",
      "308/313 [============================>.] - ETA: 0s - loss: 0.3313 - accuracy: 0.8741\n",
      "Epoch 3: val_accuracy improved from 0.84900 to 0.86060, saving model to best_model.h5\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.3319 - accuracy: 0.8736 - val_loss: 0.3823 - val_accuracy: 0.8606 - lr: 7.5786e-04\n",
      "Epoch 4/50\n",
      "308/313 [============================>.] - ETA: 0s - loss: 0.2958 - accuracy: 0.8846\n",
      "Epoch 4: val_accuracy did not improve from 0.86060\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2968 - accuracy: 0.8836 - val_loss: 0.3997 - val_accuracy: 0.8460 - lr: 6.5975e-04\n",
      "Epoch 5/50\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.2671 - accuracy: 0.9001\n",
      "Epoch 5: val_accuracy improved from 0.86060 to 0.86740, saving model to best_model.h5\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.2672 - accuracy: 0.9001 - val_loss: 0.3628 - val_accuracy: 0.8674 - lr: 5.7435e-04\n",
      "Epoch 6/50\n",
      "310/313 [============================>.] - ETA: 0s - loss: 0.2374 - accuracy: 0.9108\n",
      "Epoch 6: val_accuracy improved from 0.86740 to 0.87200, saving model to best_model.h5\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.2380 - accuracy: 0.9102 - val_loss: 0.3358 - val_accuracy: 0.8720 - lr: 5.0000e-04\n",
      "Epoch 7/50\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.2154 - accuracy: 0.9171\n",
      "Epoch 7: val_accuracy improved from 0.87200 to 0.87300, saving model to best_model.h5\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2153 - accuracy: 0.9170 - val_loss: 0.3538 - val_accuracy: 0.8730 - lr: 4.3528e-04\n",
      "Epoch 8/50\n",
      "308/313 [============================>.] - ETA: 0s - loss: 0.1930 - accuracy: 0.9284\n",
      "Epoch 8: val_accuracy improved from 0.87300 to 0.88060, saving model to best_model.h5\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.1930 - accuracy: 0.9282 - val_loss: 0.3411 - val_accuracy: 0.8806 - lr: 3.7893e-04\n",
      "Epoch 9/50\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.1746 - accuracy: 0.9342\n",
      "Epoch 9: val_accuracy did not improve from 0.88060\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.1742 - accuracy: 0.9343 - val_loss: 0.3456 - val_accuracy: 0.8754 - lr: 3.2988e-04\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.3358 - accuracy: 0.8720\n",
      "Test accuracy: 0.871999979019165\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "#Set up a ModelCheckpoint to save the best model during training\n",
    "checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_accuracy', mode='max', verbose=1)\n",
    "\n",
    "# Train the model with early stopping\n",
    "history = model.fit(train_x, train_y, epochs=50, batch_size=32, validation_data=(test_x, test_y), callbacks=[lr_scheduler,early_stopping,checkpoint])\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_x, test_y)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 6ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.79      0.83      1000\n",
      "           1       0.99      0.97      0.98      1000\n",
      "           2       0.89      0.87      0.88      1000\n",
      "           3       0.93      0.92      0.92      1000\n",
      "           4       0.70      0.81      0.75      1000\n",
      "\n",
      "    accuracy                           0.87      5000\n",
      "   macro avg       0.88      0.87      0.87      5000\n",
      "weighted avg       0.88      0.87      0.87      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(test_x)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Convert one-hot encoded true labels to class indices\n",
    "y_true_classes = np.argmax(test_y, axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_true_classes, y_pred_classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
